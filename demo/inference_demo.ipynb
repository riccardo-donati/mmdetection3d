{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from mmdet3d.apis import LidarDet3DInferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/riccardo/LidarObjDetection/mmdetection3d_dona/mmdetection3d/work_dirs/pointpillars_hv_secfpn_8xb6-160e_donaset-3d-car/iter_2500.pth\n",
      "02/16 15:36:28 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "# initialize inferencer\n",
    "inferencer = LidarDet3DInferencer('pointpillars_donaset-car')\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hv_secfpn_8xb6-160e_kittilidar-3d-car\",scope=\"mmdet3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self',\n",
       " 'inputs',\n",
       " 'preds',\n",
       " 'return_vis',\n",
       " 'show',\n",
       " 'wait_time',\n",
       " 'draw_pred',\n",
       " 'pred_score_thr',\n",
       " 'no_save_vis',\n",
       " 'img_out_dir']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "args = inspect.getfullargspec(inferencer.visualize).args\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# inference\n",
    "pcl = '../data/DonaSet/testing/velodyne/000001.bin'\n",
    "# pcl = './data/falcon/falcon1.bin'\n",
    "\n",
    "inputs = dict(points=pcl)\n",
    "# inferencer(inputs, show=False,pred_score_thr=0.3, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken 257.9369606971741\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "inferencer(inputs, show=False,pred_score_thr=0.3)\n",
    "end = time.time()\n",
    "print(\"Time Taken {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on GPU\n"
     ]
    }
   ],
   "source": [
    "# Check the device of the model\n",
    "device = next(inferencer.model.parameters()).device\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(\"Model is on GPU\")\n",
    "else:\n",
    "    print(\"Model is on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your operating environment does not have a display device,\n",
    "# (e.g. a remote server), you can save the predictions and visualize\n",
    "# them in local devices.\n",
    "inferencer(inputs, show=False, out_dir='./remote_outputs')\n",
    "\n",
    "# Simulate the migration process\n",
    "%mv ./remote_outputs ./local_outputs\n",
    "\n",
    "# Visualize the predictions from the saved files\n",
    "# NOTE: use the `Esc` key to exit Open3D window in Jupyter Notebook Environment\n",
    "local_inferencer = LidarDet3DInferencer('pointpillars_kitti-3class')\n",
    "inputs = local_inferencer._inputs_to_list(inputs)\n",
    "local_inferencer.visualize_preds_fromfile(inputs, ['local_outputs/preds/000008.json'], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 4814868\n",
      "Parameter: backbone.blocks.0.0.weight, Size: torch.Size([64, 64, 3, 3])\n",
      "Parameter: backbone.blocks.0.1.weight, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.0.1.bias, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.0.3.weight, Size: torch.Size([64, 64, 3, 3])\n",
      "Parameter: backbone.blocks.0.4.weight, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.0.4.bias, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.0.6.weight, Size: torch.Size([64, 64, 3, 3])\n",
      "Parameter: backbone.blocks.0.7.weight, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.0.7.bias, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.0.9.weight, Size: torch.Size([64, 64, 3, 3])\n",
      "Parameter: backbone.blocks.0.10.weight, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.0.10.bias, Size: torch.Size([64])\n",
      "Parameter: backbone.blocks.1.0.weight, Size: torch.Size([128, 64, 3, 3])\n",
      "Parameter: backbone.blocks.1.1.weight, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.1.bias, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.3.weight, Size: torch.Size([128, 128, 3, 3])\n",
      "Parameter: backbone.blocks.1.4.weight, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.4.bias, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.6.weight, Size: torch.Size([128, 128, 3, 3])\n",
      "Parameter: backbone.blocks.1.7.weight, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.7.bias, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.9.weight, Size: torch.Size([128, 128, 3, 3])\n",
      "Parameter: backbone.blocks.1.10.weight, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.10.bias, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.12.weight, Size: torch.Size([128, 128, 3, 3])\n",
      "Parameter: backbone.blocks.1.13.weight, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.13.bias, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.15.weight, Size: torch.Size([128, 128, 3, 3])\n",
      "Parameter: backbone.blocks.1.16.weight, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.1.16.bias, Size: torch.Size([128])\n",
      "Parameter: backbone.blocks.2.0.weight, Size: torch.Size([256, 128, 3, 3])\n",
      "Parameter: backbone.blocks.2.1.weight, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.1.bias, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.3.weight, Size: torch.Size([256, 256, 3, 3])\n",
      "Parameter: backbone.blocks.2.4.weight, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.4.bias, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.6.weight, Size: torch.Size([256, 256, 3, 3])\n",
      "Parameter: backbone.blocks.2.7.weight, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.7.bias, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.9.weight, Size: torch.Size([256, 256, 3, 3])\n",
      "Parameter: backbone.blocks.2.10.weight, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.10.bias, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.12.weight, Size: torch.Size([256, 256, 3, 3])\n",
      "Parameter: backbone.blocks.2.13.weight, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.13.bias, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.15.weight, Size: torch.Size([256, 256, 3, 3])\n",
      "Parameter: backbone.blocks.2.16.weight, Size: torch.Size([256])\n",
      "Parameter: backbone.blocks.2.16.bias, Size: torch.Size([256])\n",
      "Parameter: neck.deblocks.0.0.weight, Size: torch.Size([64, 128, 1, 1])\n",
      "Parameter: neck.deblocks.0.1.weight, Size: torch.Size([128])\n",
      "Parameter: neck.deblocks.0.1.bias, Size: torch.Size([128])\n",
      "Parameter: neck.deblocks.1.0.weight, Size: torch.Size([128, 128, 2, 2])\n",
      "Parameter: neck.deblocks.1.1.weight, Size: torch.Size([128])\n",
      "Parameter: neck.deblocks.1.1.bias, Size: torch.Size([128])\n",
      "Parameter: neck.deblocks.2.0.weight, Size: torch.Size([256, 128, 4, 4])\n",
      "Parameter: neck.deblocks.2.1.weight, Size: torch.Size([128])\n",
      "Parameter: neck.deblocks.2.1.bias, Size: torch.Size([128])\n",
      "Parameter: bbox_head.conv_cls.weight, Size: torch.Size([2, 384, 1, 1])\n",
      "Parameter: bbox_head.conv_cls.bias, Size: torch.Size([2])\n",
      "Parameter: bbox_head.conv_reg.weight, Size: torch.Size([14, 384, 1, 1])\n",
      "Parameter: bbox_head.conv_reg.bias, Size: torch.Size([14])\n",
      "Parameter: bbox_head.conv_dir_cls.weight, Size: torch.Size([4, 384, 1, 1])\n",
      "Parameter: bbox_head.conv_dir_cls.bias, Size: torch.Size([4])\n",
      "Parameter: voxel_encoder.pfn_layers.0.norm.weight, Size: torch.Size([64])\n",
      "Parameter: voxel_encoder.pfn_layers.0.norm.bias, Size: torch.Size([64])\n",
      "Parameter: voxel_encoder.pfn_layers.0.linear.weight, Size: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Count the number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "# Access and print model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name}, Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'voxels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     val_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# val_loss = loss_function(val_output, val_target)\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/base.py:88\u001b[0m, in \u001b[0;36mBase3DDetector.forward\u001b[0;34m(self, inputs, data_samples, mode, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(inputs, data_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid mode \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     91\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly supports loss, predict and tensor mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/single_stage.py:136\u001b[0m, in \u001b[0;36mSingleStage3DDetector._forward\u001b[0;34m(self, batch_inputs_dict, data_samples, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    116\u001b[0m              batch_inputs_dict: \u001b[38;5;28mdict\u001b[39m,\n\u001b[1;32m    117\u001b[0m              data_samples: OptSampleList \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    118\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Network forward process. Usually includes backbone, neck and head\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    forward without any post-processing.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        tuple[list]: A tuple of features from ``bbox_head`` forward.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/voxelnet.py:38\u001b[0m, in \u001b[0;36mVoxelNet.extract_feat\u001b[0;34m(self, batch_inputs_dict)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_feat\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_inputs_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor]:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from points.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     voxel_dict \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_inputs_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvoxels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m     voxel_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxel_encoder(voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoxels\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     40\u001b[0m                                         voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_points\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     41\u001b[0m                                         voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoors\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     42\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoors\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'voxels'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Evaluate on validation data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_output = model(inputs)\n",
    "    # val_loss = loss_function(val_output, val_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.639317  , -13.64231   ,   0.98981375,   0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = '../data/DonaSet/testing/velodyne/000001.bin'\n",
    "\n",
    "fields = 4\n",
    "# Read the binary file into a NumPy array\n",
    "data = np.fromfile(path, dtype=np.float32)\n",
    "\n",
    "# Reshape the 1D array to a 2D array with 4 columns\n",
    "data = data.reshape(-1, 4)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'voxels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 21\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/base.py:88\u001b[0m, in \u001b[0;36mBase3DDetector.forward\u001b[0;34m(self, inputs, data_samples, mode, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(inputs, data_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid mode \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     91\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly supports loss, predict and tensor mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/single_stage.py:136\u001b[0m, in \u001b[0;36mSingleStage3DDetector._forward\u001b[0;34m(self, batch_inputs_dict, data_samples, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    116\u001b[0m              batch_inputs_dict: \u001b[38;5;28mdict\u001b[39m,\n\u001b[1;32m    117\u001b[0m              data_samples: OptSampleList \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    118\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Network forward process. Usually includes backbone, neck and head\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    forward without any post-processing.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        tuple[list]: A tuple of features from ``bbox_head`` forward.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/voxelnet.py:38\u001b[0m, in \u001b[0;36mVoxelNet.extract_feat\u001b[0;34m(self, batch_inputs_dict)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_feat\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_inputs_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor]:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract features from points.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     voxel_dict \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_inputs_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvoxels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m     voxel_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxel_encoder(voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoxels\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     40\u001b[0m                                         voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_points\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     41\u001b[0m                                         voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoors\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     42\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m voxel_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoors\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'voxels'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from mmdet3d.structures import  Det3DDataSample\n",
    "# Assuming you have a single sample as a NumPy array or list\n",
    "\n",
    "# Convert the sample to a PyTorch tensor\n",
    "input_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "# Add batch dimension (if needed)\n",
    "input_tensor = input_tensor  # For models expecting a batch dimension\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "model_input = {}\n",
    "model_input[\"inputs\"] = {}\n",
    "model_input[\"inputs\"][\"points\"] = [input_tensor]\n",
    "data_sample = Det3DDataSample()\n",
    "model_input[\"data_samples\"] = [data_sample]\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model.test_step(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([64, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Print the input size of the first layer\n",
    "input_size = next(model.parameters()).size()[1:]\n",
    "print(\"Input size:\", input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'assigner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmdet3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DATASETS, MODELS\n\u001b[0;32m----> 2\u001b[0m \u001b[43mMODELS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py:232\u001b[0m, in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Sequential(\u001b[38;5;241m*\u001b[39mmodules)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/voxelnet.py:25\u001b[0m, in \u001b[0;36mVoxelNet.__init__\u001b[0;34m(self, voxel_encoder, middle_encoder, backbone, neck, bbox_head, train_cfg, test_cfg, data_preprocessor, init_cfg)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     16\u001b[0m              voxel_encoder: ConfigType,\n\u001b[1;32m     17\u001b[0m              middle_encoder: ConfigType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m              data_preprocessor: OptConfigType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m              init_cfg: OptMultiConfig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbbox_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_preprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_preprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxel_encoder \u001b[38;5;241m=\u001b[39m MODELS\u001b[38;5;241m.\u001b[39mbuild(voxel_encoder)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddle_encoder \u001b[38;5;241m=\u001b[39m MODELS\u001b[38;5;241m.\u001b[39mbuild(middle_encoder)\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/detectors/single_stage.py:52\u001b[0m, in \u001b[0;36mSingleStage3DDetector.__init__\u001b[0;34m(self, backbone, neck, bbox_head, train_cfg, test_cfg, data_preprocessor, init_cfg)\u001b[0m\n\u001b[1;32m     50\u001b[0m bbox_head\u001b[38;5;241m.\u001b[39mupdate(train_cfg\u001b[38;5;241m=\u001b[39mtrain_cfg)\n\u001b[1;32m     51\u001b[0m bbox_head\u001b[38;5;241m.\u001b[39mupdate(test_cfg\u001b[38;5;241m=\u001b[39mtest_cfg)\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head \u001b[38;5;241m=\u001b[39m \u001b[43mMODELS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox_head\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_cfg \u001b[38;5;241m=\u001b[39m train_cfg\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_cfg \u001b[38;5;241m=\u001b[39m test_cfg\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py:232\u001b[0m, in \u001b[0;36mbuild_model_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Sequential(\u001b[38;5;241m*\u001b[39mmodules)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/pytorch_cuda123_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:118\u001b[0m, in \u001b[0;36mAnchor3DHead.__init__\u001b[0;34m(self, num_classes, in_channels, feat_channels, use_direction_classifier, anchor_generator, assigner_per_size, assign_per_class, diff_rad_by_sin, dir_offset, dir_limit_offset, bbox_coder, loss_cls, loss_bbox, loss_dir, train_cfg, test_cfg, init_cfg)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_dir \u001b[38;5;241m=\u001b[39m MODELS\u001b[38;5;241m.\u001b[39mbuild(loss_dir)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_layers()\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_assigner_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    123\u001b[0m         layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv2d\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    124\u001b[0m         std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m    125\u001b[0m         override\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_cls\u001b[39m\u001b[38;5;124m'\u001b[39m, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, bias_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m))\n",
      "File \u001b[0;32m~/LidarObjDetection/mmdetection3d_dona/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:137\u001b[0m, in \u001b[0;36mAnchor3DHead._init_assigner_sampler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_sampler \u001b[38;5;241m=\u001b[39m PseudoSampler()\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massigner\u001b[49m, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_assigner \u001b[38;5;241m=\u001b[39m TASK_UTILS\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39massigner)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39massigner, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'assigner'"
     ]
    }
   ],
   "source": [
    "from mmdet3d.registry import DATASETS, MODELS\n",
    "MODELS.build(mod)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0c343fece975dd89087e8c2194dd4d3db28d7000f1b32ed9ed9d584dd54dbbe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
