{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home/riccardo/mmdetection3d\")\n",
    "# sys.path.append(\"/root/workspace/mmdeploy\")\n",
    "from mmdet3d.apis import LidarDet3DInferencer\n",
    "from mmdeploy.apis.inference import inference_model\n",
    "from mmdeploy.apis.inference import get_model\n",
    "import os\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "import onnxruntime as ort\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/riccardo/LidarObjDetection2/mmdetection3d/work_dirs/pointpillars_hydra_custom/iter_3000.pth\n",
      "07/08 16:59:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "# initialize inferencer \n",
    "# execute >> pip install -v -e . in mmdetection3d folder \n",
    "# CHANGE THE center_mode in loca_visualizer accordingly (KITTI -> center_mode = 'lidar_bottom', CUSTOM -> center_mode = whatever)\n",
    "\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car')\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_donaset_container-car')\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_kittilidar-car') \n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hv_secfpn_8xb6-160e_lidar_vegas_iris-3d-car\",scope=\"mmdet3d\")\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_lidar_vegas_iris-car_360\",scope=\"mmdet3d\")\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hydris_car\",scope=\"mmdet3d\")\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hydris_car\",scope=\"mmdet3d\")\n",
    "inferencer = LidarDet3DInferencer(\"pointpillars_hydra_custom_3000\",scope=\"mmdet3d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination folder '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation' created.\n",
      "Copied '000428.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000083.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000363.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000111.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000443.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000437.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000330.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000439.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000421.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000035.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000521.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000036.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000256.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000335.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000297.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000008.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000436.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000131.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000328.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000072.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000105.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000241.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000487.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000295.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000513.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000393.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000228.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000188.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000250.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000087.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000478.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000134.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000254.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000403.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000215.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000559.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000120.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000320.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000550.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000544.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000317.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000163.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000453.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000545.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000518.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000440.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000222.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000202.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000040.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000258.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000247.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000413.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000249.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000147.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000287.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000177.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000385.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def copy_bin_files(source_txt, bin_folder_path,destination_folder):\n",
    "\n",
    "\n",
    "  # Check if source text file exists\n",
    "  if not os.path.exists(source_txt):\n",
    "    print(f\"Error: Source text file '{source_txt}' does not exist.\")\n",
    "    return\n",
    "\n",
    "  # Check if destination folder exists, create it if not\n",
    "  if not os.path.exists(destination_folder):\n",
    "    try:\n",
    "      os.makedirs(destination_folder)\n",
    "      print(f\"Destination folder '{destination_folder}' created.\")\n",
    "    except OSError as e:\n",
    "      print(f\"Error creating destination folder: {e}\")\n",
    "      return\n",
    "\n",
    "  # Open the source text file\n",
    "  try:\n",
    "    with open(source_txt, 'r') as file:\n",
    "      lines = file.readlines()\n",
    "  except OSError as e:\n",
    "    print(f\"Error opening source text file: {e}\")\n",
    "    return\n",
    "\n",
    "  # Process each line in the text file\n",
    "  for line in lines:\n",
    "    # Remove leading/trailing whitespace and newline character\n",
    "    filename = line.strip() +\".bin\"\n",
    "\n",
    "    # Check if the filename ends with .bin\n",
    "    if not filename.endswith('.bin'):\n",
    "      print(f\"Warning: Skipping non-binary file '{filename}'.\")\n",
    "      continue\n",
    "\n",
    "    # Construct source and destination paths\n",
    "    source_path = os.path.join(bin_folder_path, filename)\n",
    "    dest_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "    # Check if source file exists\n",
    "    if not os.path.exists(source_path):\n",
    "      print(f\"Warning: Source file '{source_path}' does not exist. Skipping...\")\n",
    "      continue\n",
    "\n",
    "    # Copy the file\n",
    "    try:\n",
    "      with open(source_path, 'rb') as source, open(dest_path, 'wb') as destination:\n",
    "        for chunk in iter(lambda: source.read(1024), b''):\n",
    "          destination.write(chunk)\n",
    "      print(f\"Copied '{filename}' to '{destination_folder}'.\")\n",
    "    except OSError as e:\n",
    "      print(f\"Error copying file '{filename}': {e}\")\n",
    "\n",
    "# Example usage\n",
    "source_txt_path = dataset_dir +\"/ImageSets/val.txt\"  # Replace with your actual path\n",
    "destination_folder_path = dataset_dir +\"/validation\"  # Replace with your actual path\n",
    "bin_folder_path = dataset_dir +\"/training/velodyne\"\n",
    "copy_bin_files(source_txt_path, bin_folder_path, destination_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer = LidarDet3DInferencer(\"pointpillars_hydra_custom_3000\",scope=\"mmdet3d\")\n",
    "pcl = os.path.join(dataset_dir,\"validation\")\n",
    "for file in os.listdir(pcl):\n",
    "    print(file)\n",
    "    inputs = dict(points=os.path.join(pcl,file))\n",
    "    inf_res = inferencer(inputs, show=False,pred_score_thr=0.2, batch_size=1)\n",
    "    break\n",
    "inf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000413.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "000228.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000241.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000163.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000040.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000335.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000247.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: The GLFW library is not initialized\u001b[0;m\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "# pcl = '../data/Dataset_Lidar_20240111_vegas_ontrack_01/validation'\n",
    "pcl = os.path.join(dataset_dir,\"validation\")\n",
    "# pcl = os.path.join(dataset_dir,\"training\",\"velodyne\")\n",
    "# pcl = '../data/Hydra/training/velodyne/000020.bin'\n",
    "# pcl = '../data/DonaSet/training/velodyne/'\n",
    "# # pcl = './data/falcon/falcon1.bin'\n",
    "# inputs = dict(points=pcl)\n",
    "# inf_res = inferencer(inputs, show=True,pred_score_thr=0.3, batch_size=1)\n",
    "# inf_res\n",
    "\n",
    "for file in os.listdir(pcl):\n",
    "    print(file)\n",
    "    inputs = dict(points=os.path.join(pcl,file))\n",
    "    inf_res = inferencer(inputs, show=True,pred_score_thr=0.2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "inferencer(inputs, show=False,pred_score_thr=0.3,batch_size=1)\n",
    "end = time.time()\n",
    "print(\"Time Taken {} ms\".format((end-start)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                 LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "import os \n",
    "\n",
    "def prepare_input(inputs,batch_size=1):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000)))\n",
    "\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if i == max-1:\n",
    "            print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "s = time.time()\n",
    "\n",
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1) # Preprocess\n",
    "res = model(prep_input[\"inputs\"],prep_input[\"data_samples\"], mode=\"tensor\") # Forward\n",
    "preds  = model.bbox_head.predict_by_feat(*res) # Postprocess\n",
    "\n",
    "print(\"Time: {} ms\".format((time.time()-s)*1000))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_res = inferencer(inputs, show=False,pred_score_thr=0.3, batch_size=4)\n",
    "inf_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Manually the tensor to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.models.dense_heads.anchor3d_head import Anchor3DHead\n",
    "\n",
    "# bbox_head=dict(\n",
    "#     type='Anchor3DHead',\n",
    "#     num_classes=3,\n",
    "#     in_channels=384,\n",
    "#     feat_channels=384,\n",
    "#     use_direction_classifier=True,\n",
    "#     assign_per_class=True,\n",
    "#     anchor_generator=dict(\n",
    "#         type='AlignedAnchor3DRangeGenerator',\n",
    "#         ranges=[\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -1.78, 69.12, 39.68, -1.78],\n",
    "#         ],\n",
    "#         sizes=[[0.8, 0.6, 1.73], [1.76, 0.6, 1.73], [3.9, 1.6, 1.56]],\n",
    "#         rotations=[0, 1.57],\n",
    "#         reshape_out=False),\n",
    "#     diff_rad_by_sin=True,\n",
    "#     bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder')\n",
    "# )\n",
    "# model.bbox_head\n",
    "head = Anchor3DHead(\n",
    "    num_classes=1,\n",
    "    in_channels=384,\n",
    "    feat_channels=384,\n",
    "    use_direction_classifier=True,\n",
    "    assign_per_class=True,\n",
    "    anchor_generator=dict(\n",
    "                type='AlignedAnchor3DRangeGenerator',\n",
    "                ranges=[[0, -39.68, -1.78, 69.12, 39.68, -1.78]],\n",
    "                sizes=[[3.9, 1.6, 1.56]],\n",
    "                rotations=[0, 1.57],\n",
    "                reshape_out=True),\n",
    "    diff_rad_by_sin=True,\n",
    "    bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'),\n",
    "    test_cfg=model.test_cfg\n",
    "    )\n",
    "# preds  = head.predict_by_feat(*res)\n",
    "preds  = model.bbox_head.predict_by_feat(*res)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][\"bboxes_3d\"],pred_res[0][\"bboxes_3d\"],inf_res[\"predictions\"][0][\"bboxes_3d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n",
    "pcl_path = os.path.join(dataset_dir, \"training/velodyne/000020.bin\")\n",
    "model_path = \"deployed_models/hydris/end2end.onnx\"\n",
    "model_cfg = \"../configs/pointpillars/pointpillars_hydris_car.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, model_cfg = None, device=\"cuda\",data_samples=False, deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        cfg = Config.fromfile(model_cfg)\n",
    "        cfg[\"model\"][\"data_preprocessor\"].pop(\"type\")\n",
    "        preprocessor = Det3DDataPreprocessor(**cfg[\"model\"][\"data_preprocessor\"])\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = time.time()\n",
    "model.cpu()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg=model_cfg,device = \"cpu\")[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = time.time()\n",
    "model.cuda()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg =  model_cfg, deterministic=True)[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Provider (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0= time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg = model_cfg, device=\"cuda\")[\"inputs\"]\n",
    "\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy().astype(np.float32), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "outputs = [arr.astype(np.float32) for arr in outputs]\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Provider (ONNX Runtime) - FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxconverter_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import load\n",
    "from onnxmltools.utils.float16_converter import convert_float_to_float16\n",
    "from onnx import save\n",
    "onnx_model = load(model_path)\n",
    "new_onnx_model = convert_float_to_float16(onnx_model)\n",
    "save(new_onnx_model,\"deployed_models/hydra/end2end_fp16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(\"deployed_models/hydra/end2end_fp16.onnx\",providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0= time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg = model_cfg,device=\"cuda\")[\"inputs\"]\n",
    "\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy().astype(np.float16), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "outputs = [arr.astype(np.float32) for arr in outputs]\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=[ 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, model_cfg = None, device=\"cuda\",data_samples=False, preprocessor=None,deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    # print(preprocessor.device)\n",
    "    s0 = time.time()\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    # print((time.time()-s0)*1000)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "07/03 23:31:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "07/03 23:31:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"mmdet3d_tasks\" registry tree. As a workaround, the current \"mmdet3d_tasks\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "07/03 23:31:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"backend_voxel_detectors\" registry tree. As a workaround, the current \"backend_voxel_detectors\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "07/03 23:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n",
      "07/03 23:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_cfg = \"../configs/pointpillars/pointpillars_hydris_car.py\"\n",
    "deploy_cfg = \"../../mmdeploy/configs/mmdet3d/voxel-detection/voxel-detection_tensorrt_dynamic-kitti-32x4_fp16.py\"\n",
    "backend_files = \"deployed_models/hydris/end2end_fp16.engine\"\n",
    "img = os.path.join(dataset_dir,\"training/velodyne/000000.bin\")\n",
    "device = \"cuda\"\n",
    "\n",
    "tensorrt_model = get_model(model_cfg,deploy_cfg,[backend_files],img,device)\n",
    "preprocessor = tensorrt_model.data_preprocessor.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# combined_tensor = torch.cat([res[\"bbox_pred\"][0], res[\"cls_score\"][0], res[\"dir_cls_pred\"][0]], dim=0)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# combined_cpu = combined_tensor.cpu()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m s2 \u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 15\u001b[0m preds  \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39mpredict_by_feat(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls_score\u001b[39m\u001b[38;5;124m\"\u001b[39m],res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m],res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdir_cls_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((s1\u001b[38;5;241m-\u001b[39ms0)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInf: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((s2\u001b[38;5;241m-\u001b[39ms1)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pcl_path =  os.path.join(dataset_dir,\"training/velodyne/000020.bin\")\n",
    "\n",
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, preprocessor = preprocessor, data_samples=False)[\"inputs\"]\n",
    "# inputs = prepare_input_fast({\"points\": pcl_path}, batch_size=1, data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "res[\"bbox_pred\"][0] = res[\"bbox_pred\"][0].to(\"cpu\",non_blocking=True)\n",
    "res[\"cls_score\"][0] = res[\"cls_score\"][0].to(\"cpu\",non_blocking=True)\n",
    "res[\"dir_cls_pred\"][0] = res[\"dir_cls_pred\"][0].to(\"cpu\",non_blocking=True)\n",
    "# combined_tensor = torch.cat([res[\"bbox_pred\"][0], res[\"cls_score\"][0], res[\"dir_cls_pred\"][0]], dim=0)\n",
    "# combined_cpu = combined_tensor.cpu()\n",
    "s2 =time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Inferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmengine.config import Config\n",
    "from mmdet3d.models.dense_heads import Anchor3DHead\n",
    "\n",
    "cfg = Config.fromfile(model_cfg)\n",
    "\n",
    "cfg[\"model\"][\"bbox_head\"].pop(\"type\")\n",
    "bbox_head = Anchor3DHead(**cfg[\"model\"][\"bbox_head\"])\n",
    "bbox_head.test_cfg = cfg[\"model\"][\"test_cfg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 5.93256950378418 ms\n",
      "Inf: 15.146017074584961 ms\n",
      "Post: 3.1936168670654297 ms\n",
      "Total: 24.293184280395508 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, preprocessor=preprocessor,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "torch.cuda.synchronize()\n",
    "s2 =time.time()\n",
    "preds  = bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT manual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "def load_engine(engine_file_path):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_file_path, 'rb') as f:\n",
    "        runtime = trt.Runtime(TRT_LOGGER)\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    return engine\n",
    "def torch_dtype_from_trt(dtype: trt.DataType) -> torch.dtype:\n",
    "    \"\"\"Convert pytorch dtype to TensorRT dtype.\n",
    "\n",
    "    Args:\n",
    "        dtype (str.DataType): The data type in tensorrt.\n",
    "\n",
    "    Returns:\n",
    "        torch.dtype: The corresponding data type in torch.\n",
    "    \"\"\"\n",
    "\n",
    "    if dtype == trt.bool:\n",
    "        return torch.bool\n",
    "    elif dtype == trt.int8:\n",
    "        return torch.int8\n",
    "    elif dtype == trt.int32:\n",
    "        return torch.int32\n",
    "    elif dtype == trt.float16:\n",
    "        return torch.float16\n",
    "    elif dtype == trt.float32:\n",
    "        return torch.float32\n",
    "    else:\n",
    "        raise TypeError(f'{dtype} is not supported by torch')\n",
    "\n",
    "\n",
    "def torch_device_from_trt(device: trt.TensorLocation):\n",
    "    \"\"\"Convert pytorch device to TensorRT device.\n",
    "\n",
    "    Args:\n",
    "        device (trt.TensorLocation): The device in tensorrt.\n",
    "    Returns:\n",
    "        torch.device: The corresponding device in torch.\n",
    "    \"\"\"\n",
    "    if device == trt.TensorLocation.DEVICE:\n",
    "        return torch.device('cuda')\n",
    "    elif device == trt.TensorLocation.HOST:\n",
    "        return torch.device('cpu')\n",
    "    else:\n",
    "        return TypeError(f'{device} is not supported by torch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcl_path =  os.path.join(dataset_dir,\"training/velodyne/000020.bin\")\n",
    "backend_files = \"deployed_models/hydris/end2end_fp16.engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322058/2476830997.py:4: DeprecationWarning: Use get_tensor_name instead.\n",
      "  input_names = [engine.get_binding_name(i) for i in range(n_inputs)]\n",
      "/tmp/ipykernel_322058/2476830997.py:5: DeprecationWarning: Use get_tensor_name instead.\n",
      "  output_names = [engine.get_binding_name(i) for i in range(n_inputs,n_inputs+n_outputs)]\n"
     ]
    }
   ],
   "source": [
    "n_inputs  = 3\n",
    "n_outputs = 3\n",
    "engine = load_engine(backend_files)\n",
    "input_names = [engine.get_binding_name(i) for i in range(n_inputs)]\n",
    "output_names = [engine.get_binding_name(i) for i in range(n_inputs,n_inputs+n_outputs)]\n",
    "\n",
    "# Create context\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(pcl_path):\n",
    "    bindings = [None] * (n_inputs + n_outputs)\n",
    "\n",
    "    # Transform Input\n",
    "    inputs = prepare_input({\"points\": pcl_path}, batch_size=1, preprocessor=preprocessor,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "    preprocessed = inputs['voxels']\n",
    "    input_dict = {\n",
    "        'voxels': preprocessed['voxels'].to(\"cuda\"),\n",
    "        'num_points': preprocessed['num_points'].to(\"cuda\"),\n",
    "        'coors': preprocessed['coors'].to(\"cuda\")\n",
    "    }\n",
    "    inputs = dict((name, data.contiguous().int() if data.dtype ==\n",
    "                        torch.long else data.contiguous())\n",
    "                        for name, data in input_dict.items())\n",
    "\n",
    "    for input_name in input_names:\n",
    "        idx = engine.get_binding_index(input_name)\n",
    "        profile = engine.get_profile_shape(0, input_name)\n",
    "        input_tensor = inputs[input_name]\n",
    "        context.set_binding_shape(idx, tuple(input_tensor.shape))\n",
    "        bindings[idx] = input_tensor.contiguous().data_ptr()\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = {}\n",
    "    for output_name in output_names:\n",
    "        idx = engine.get_binding_index(output_name)\n",
    "\n",
    "        dtype = torch_dtype_from_trt(engine.get_binding_dtype(idx))\n",
    "        shape = tuple(context.get_binding_shape(idx))\n",
    "\n",
    "        device = torch_device_from_trt(engine.get_location(idx))\n",
    "        output = torch.empty(size=shape, dtype=dtype, device=device)\n",
    "        outputs[output_name] = output\n",
    "        bindings[idx] = output.contiguous().data_ptr()\n",
    "\n",
    "    context.execute_async_v2(bindings,\n",
    "                            torch.cuda.current_stream().cuda_stream)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 20.28489112854004 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322058/1935469659.py:17: DeprecationWarning: Use get_tensor_name instead.\n",
      "  idx = engine.get_binding_index(input_name)\n",
      "/tmp/ipykernel_322058/1935469659.py:18: DeprecationWarning: Use get_tensor_profile_shape instead.\n",
      "  profile = engine.get_profile_shape(0, input_name)\n",
      "/tmp/ipykernel_322058/1935469659.py:20: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(idx, tuple(input_tensor.shape))\n",
      "/tmp/ipykernel_322058/1935469659.py:26: DeprecationWarning: Use get_tensor_name instead.\n",
      "  idx = engine.get_binding_index(output_name)\n",
      "/tmp/ipykernel_322058/1935469659.py:28: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = torch_dtype_from_trt(engine.get_binding_dtype(idx))\n",
      "/tmp/ipykernel_322058/1935469659.py:29: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shape = tuple(context.get_binding_shape(idx))\n",
      "/tmp/ipykernel_322058/1935469659.py:31: DeprecationWarning: Use get_tensor_location instead.\n",
      "  device = torch_device_from_trt(engine.get_location(idx))\n"
     ]
    }
   ],
   "source": [
    "s0=time.time()\n",
    "do_inference(pcl_path)\n",
    "torch.cuda.synchronize()\n",
    "print(\"Took \"+str((time.time()-s0)*1e3)+\" ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "context.execute_async_v2(bindings,\n",
    "                        torch.cuda.current_stream().cuda_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 124, 436])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"cls_score0\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model_cfg = \"../configs/pointpillars/pointpillars_hydris_car.py\"\n",
    "deploy_cfg = \"../../mmdeploy/configs/mmdet3d/voxel-detection/voxel-detection_tensorrt_dynamic-kitti-32x4_fp16.py\"\n",
    "backend_files = \"deployed_models/hydra/end2end_fp16.engine\"\n",
    "img =  os.path.join(dataset_dir,\"velodyne/000000.bin\")\n",
    "device = \"cuda\"\n",
    "\n",
    "tensorrt_model = get_model(model_cfg,deploy_cfg,[backend_files],img,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "s2 =time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dict(points=pcl)\n",
    "inf_res = inferencer(inputs, show=True, pred_score_thr=0.3, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.structures import Det3DDataSample\n",
    "\n",
    "inputs = prepare_input({\"points\": pcl}, batch_size=1,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "preds = tensorrt_model(inputs, mode=\"predict\")\n",
    "ds = Det3DDataSample()\n",
    "ds.pred_instances_3d = preds[0]\n",
    "\n",
    "inferencer.visualize([{\"points\": pcl}], [ds],show=True,pred_score_thr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(ds.pred_instances_3d.bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelization algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.models.data_preprocessors import Det3DDataPreprocessor\n",
    "\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, device=\"cuda\",data_samples=False, deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[-60, -19.84, -3, 79.52, 19.84, 3],\n",
    "                # point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 3],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000),\n",
    "                deterministic=deterministic))\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False, deterministic=False, device=\"cuda\")[\"inputs\"]\n",
    "print(\"Non deterministic voxel -> \" +str((time.time()-s0)*1000))\n",
    "\n",
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False, deterministic=True, device=\"cuda\")[\"inputs\"]\n",
    "print(\"Deterministic voxel -> \" +str((time.time()-s0)*1000))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0c343fece975dd89087e8c2194dd4d3db28d7000f1b32ed9ed9d584dd54dbbe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
