{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home/riccardo/mmdetection3d\")\n",
    "# sys.path.append(\"/root/workspace/mmdeploy\")\n",
    "from mmdet3d.apis import LidarDet3DInferencer\n",
    "from mmdeploy.apis.inference import inference_model\n",
    "from mmdeploy.apis.inference import get_model\n",
    "import os\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "import onnxruntime as ort\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/riccardo/LidarObjDetection2/mmdetection3d/work_dirs/pointpillars_hydris_car/iter_6500.pth\n",
      "06/11 10:53:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "# initialize inferencer \n",
    "# execute >> pip install -v -e . in mmdetection3d folder \n",
    "# CHANGE THE center_mode in loca_visualizer accordingly (KITTI -> center_mode = 'lidar_bottom', CUSTOM -> center_mode = whatever)\n",
    "\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car')\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_donaset_container-car')\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_kittilidar-car') \n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hv_secfpn_8xb6-160e_lidar_vegas_iris-3d-car\",scope=\"mmdet3d\")\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_lidar_vegas_iris-car_360\",scope=\"mmdet3d\")\n",
    "inferencer = LidarDet3DInferencer(\"pointpillars_hydris_car\",scope=\"mmdet3d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Det3DDataPreprocessor(\n",
       "  (voxel_layer): VoxelizationByGridShape(voxel_size=[0.16, 0.16, 6], grid_shape=[872, 248, 1], point_cloud_range=[-60, -19.84, -3, 79.52, 19.84, 3], max_num_points=32, max_voxels=(16000, 40000), deterministic=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencer.model.data_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/Hydris/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error copying file '000043.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000043.bin'\n",
      "Error copying file '000295.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000295.bin'\n",
      "Error copying file '000139.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000139.bin'\n",
      "Error copying file '000150.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000150.bin'\n",
      "Error copying file '000255.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000255.bin'\n",
      "Error copying file '000079.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000079.bin'\n",
      "Error copying file '000431.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000431.bin'\n",
      "Error copying file '000126.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000126.bin'\n",
      "Error copying file '000056.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000056.bin'\n",
      "Error copying file '000355.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000355.bin'\n",
      "Error copying file '000477.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000477.bin'\n",
      "Error copying file '000538.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000538.bin'\n",
      "Error copying file '000101.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000101.bin'\n",
      "Error copying file '000326.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000326.bin'\n",
      "Error copying file '000134.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000134.bin'\n",
      "Error copying file '000537.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000537.bin'\n",
      "Error copying file '000320.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000320.bin'\n",
      "Error copying file '000282.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000282.bin'\n",
      "Error copying file '000063.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000063.bin'\n",
      "Error copying file '000551.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000551.bin'\n",
      "Error copying file '000342.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000342.bin'\n",
      "Error copying file '000581.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000581.bin'\n",
      "Error copying file '000044.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000044.bin'\n",
      "Error copying file '000285.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000285.bin'\n",
      "Error copying file '000335.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000335.bin'\n",
      "Error copying file '000585.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000585.bin'\n",
      "Error copying file '000429.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000429.bin'\n",
      "Error copying file '000583.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000583.bin'\n",
      "Error copying file '000003.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000003.bin'\n",
      "Error copying file '000486.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000486.bin'\n",
      "Error copying file '000265.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000265.bin'\n",
      "Error copying file '000001.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000001.bin'\n",
      "Error copying file '000316.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000316.bin'\n",
      "Error copying file '000241.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000241.bin'\n",
      "Error copying file '000565.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000565.bin'\n",
      "Error copying file '000284.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000284.bin'\n",
      "Error copying file '000476.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000476.bin'\n",
      "Error copying file '000492.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000492.bin'\n",
      "Error copying file '000039.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000039.bin'\n",
      "Error copying file '000464.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000464.bin'\n",
      "Error copying file '000105.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000105.bin'\n",
      "Error copying file '000283.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000283.bin'\n",
      "Error copying file '000179.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000179.bin'\n",
      "Error copying file '000467.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000467.bin'\n",
      "Error copying file '000085.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000085.bin'\n",
      "Error copying file '000223.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000223.bin'\n",
      "Error copying file '000190.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000190.bin'\n",
      "Error copying file '000470.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000470.bin'\n",
      "Error copying file '000246.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000246.bin'\n",
      "Error copying file '000553.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000553.bin'\n",
      "Error copying file '000219.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000219.bin'\n",
      "Error copying file '000263.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000263.bin'\n",
      "Error copying file '000394.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000394.bin'\n",
      "Error copying file '000238.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000238.bin'\n",
      "Error copying file '000525.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000525.bin'\n",
      "Error copying file '000423.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000423.bin'\n",
      "Error copying file '000396.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000396.bin'\n",
      "Error copying file '000356.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000356.bin'\n",
      "Error copying file '000427.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000427.bin'\n",
      "Error copying file '000149.bin': [Errno 13] Permission denied: '../data/Hydris//validation/000149.bin'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def copy_bin_files(source_txt, bin_folder_path,destination_folder):\n",
    "\n",
    "\n",
    "  # Check if source text file exists\n",
    "  if not os.path.exists(source_txt):\n",
    "    print(f\"Error: Source text file '{source_txt}' does not exist.\")\n",
    "    return\n",
    "\n",
    "  # Check if destination folder exists, create it if not\n",
    "  if not os.path.exists(destination_folder):\n",
    "    try:\n",
    "      os.makedirs(destination_folder)\n",
    "      print(f\"Destination folder '{destination_folder}' created.\")\n",
    "    except OSError as e:\n",
    "      print(f\"Error creating destination folder: {e}\")\n",
    "      return\n",
    "\n",
    "  # Open the source text file\n",
    "  try:\n",
    "    with open(source_txt, 'r') as file:\n",
    "      lines = file.readlines()\n",
    "  except OSError as e:\n",
    "    print(f\"Error opening source text file: {e}\")\n",
    "    return\n",
    "\n",
    "  # Process each line in the text file\n",
    "  for line in lines:\n",
    "    # Remove leading/trailing whitespace and newline character\n",
    "    filename = line.strip() +\".bin\"\n",
    "\n",
    "    # Check if the filename ends with .bin\n",
    "    if not filename.endswith('.bin'):\n",
    "      print(f\"Warning: Skipping non-binary file '{filename}'.\")\n",
    "      continue\n",
    "\n",
    "    # Construct source and destination paths\n",
    "    source_path = os.path.join(bin_folder_path, filename)\n",
    "    dest_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "    # Check if source file exists\n",
    "    if not os.path.exists(source_path):\n",
    "      print(f\"Warning: Source file '{source_path}' does not exist. Skipping...\")\n",
    "      continue\n",
    "\n",
    "    # Copy the file\n",
    "    try:\n",
    "      with open(source_path, 'rb') as source, open(dest_path, 'wb') as destination:\n",
    "        for chunk in iter(lambda: source.read(1024), b''):\n",
    "          destination.write(chunk)\n",
    "      print(f\"Copied '{filename}' to '{destination_folder}'.\")\n",
    "    except OSError as e:\n",
    "      print(f\"Error copying file '{filename}': {e}\")\n",
    "\n",
    "# Example usage\n",
    "source_txt_path = dataset_dir +\"/ImageSets/val.txt\"  # Replace with your actual path\n",
    "destination_folder_path = dataset_dir +\"/validation\"  # Replace with your actual path\n",
    "bin_folder_path = dataset_dir +\"/training/velodyne\"\n",
    "copy_bin_files(source_txt_path, bin_folder_path, destination_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: The GLFW library is not initialized\u001b[0;m\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "# pcl = '../data/Dataset_Lidar_20240111_vegas_ontrack_01/validation'\n",
    "pcl = os.path.join(dataset_dir,\"validation\")\n",
    "# pcl = '../data/DonaSet/training/velodyne/'\n",
    "# pcl = './data/falcon/falcon1.bin'\n",
    "inputs = dict(points=pcl)\n",
    "inf_res = inferencer(inputs, show=True,pred_score_thr=0.3, batch_size=1)\n",
    "inf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken 112.63775825500488 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "inferencer(inputs, show=False,pred_score_thr=0.3,batch_size=1)\n",
    "end = time.time()\n",
    "print(\"Time Taken {} ms\".format((end-start)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                 LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "import os \n",
    "\n",
    "def prepare_input(inputs,batch_size=1):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000)))\n",
    "\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if i == max-1:\n",
    "            print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "s = time.time()\n",
    "\n",
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1) # Preprocess\n",
    "res = model(prep_input[\"inputs\"],prep_input[\"data_samples\"], mode=\"tensor\") # Forward\n",
    "preds  = model.bbox_head.predict_by_feat(*res) # Postprocess\n",
    "\n",
    "print(\"Time: {} ms\".format((time.time()-s)*1000))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_res = inferencer(inputs, show=False,pred_score_thr=0.3, batch_size=4)\n",
    "inf_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Manually the tensor to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.models.dense_heads.anchor3d_head import Anchor3DHead\n",
    "\n",
    "# bbox_head=dict(\n",
    "#     type='Anchor3DHead',\n",
    "#     num_classes=3,\n",
    "#     in_channels=384,\n",
    "#     feat_channels=384,\n",
    "#     use_direction_classifier=True,\n",
    "#     assign_per_class=True,\n",
    "#     anchor_generator=dict(\n",
    "#         type='AlignedAnchor3DRangeGenerator',\n",
    "#         ranges=[\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -1.78, 69.12, 39.68, -1.78],\n",
    "#         ],\n",
    "#         sizes=[[0.8, 0.6, 1.73], [1.76, 0.6, 1.73], [3.9, 1.6, 1.56]],\n",
    "#         rotations=[0, 1.57],\n",
    "#         reshape_out=False),\n",
    "#     diff_rad_by_sin=True,\n",
    "#     bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder')\n",
    "# )\n",
    "# model.bbox_head\n",
    "head = Anchor3DHead(\n",
    "    num_classes=1,\n",
    "    in_channels=384,\n",
    "    feat_channels=384,\n",
    "    use_direction_classifier=True,\n",
    "    assign_per_class=True,\n",
    "    anchor_generator=dict(\n",
    "                type='AlignedAnchor3DRangeGenerator',\n",
    "                ranges=[[0, -39.68, -1.78, 69.12, 39.68, -1.78]],\n",
    "                sizes=[[3.9, 1.6, 1.56]],\n",
    "                rotations=[0, 1.57],\n",
    "                reshape_out=True),\n",
    "    diff_rad_by_sin=True,\n",
    "    bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'),\n",
    "    test_cfg=model.test_cfg\n",
    "    )\n",
    "# preds  = head.predict_by_feat(*res)\n",
    "preds  = model.bbox_head.predict_by_feat(*res)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][\"bboxes_3d\"],pred_res[0][\"bboxes_3d\"],inf_res[\"predictions\"][0][\"bboxes_3d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n",
    "pcl_path = \"../data/Dataset_Lidar_20240111_vegas_ontrack_01/training/velodyne/000050.bin\"\n",
    "model_path = \"deployed_models/iris_360_2/end2end.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(inputs,batch_size=1, device=\"cuda\",data_samples=False, deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[-60, -19.84, -3, 79.52, 19.84, 3],\n",
    "                # point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 3],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000),\n",
    "                deterministic=deterministic))\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 4.081964492797852 ms\n",
      "Inf: 260.21838188171387 ms\n",
      "Post: 2.9685497283935547 ms\n",
      "Total: 263.20791244506836 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "model.cpu()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, device = \"cpu\")[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 4.9419403076171875 ms\n",
      "Inf: 16.715526580810547 ms\n",
      "Post: 33.89549255371094 ms\n",
      "Total: 50.63295364379883 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "model.cuda()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,deterministic=True)[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Provider (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 12:46:40.493606214 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:46:40 WARNING] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "2024-06-10 12:46:40.493627167 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:46:40 WARNING] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n",
      "2024-06-10 12:46:40.598072051 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:46:40 WARNING] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "2024-06-10 12:46:40.598253319 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:46:40 WARNING] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n"
     ]
    }
   ],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Provider (ONNX Runtime) - FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import load\n",
    "from onnxmltools.utils.float16_converter import convert_float_to_float16\n",
    "from onnx import save\n",
    "onnx_model = load(model_path)\n",
    "new_onnx_model = convert_float_to_float16(onnx_model)\n",
    "save(new_onnx_model,\"end2end_fp16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 12:45:57.429920415 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:45:57 WARNING] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "2024-06-10 12:45:57.429948420 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:45:57 WARNING] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n",
      "2024-06-10 12:46:01.681154268 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:46:01 WARNING] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "2024-06-10 12:46:01.681176955 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-06-10 10:46:01 WARNING] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n"
     ]
    }
   ],
   "source": [
    "ort_sess = ort.InferenceSession(\"deployed_models/iris_front/end2end_fp16.onnx\",providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 45.86482048034668 ms\n",
      "Inf: 37.64224052429199 ms\n",
      "Post: 33.80393981933594 ms\n",
      "Total: 117.63334274291992 ms\n"
     ]
    }
   ],
   "source": [
    "s0= time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,device=\"cuda\")[\"inputs\"]\n",
    "\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy().astype(np.float16), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "outputs = [arr.astype(np.float32) for arr in outputs]\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inf: 68.58515739440918 ms\n",
      "Post: 15.950441360473633 ms\n",
      "Total: 84.56301689147949 ms\n"
     ]
    }
   ],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=[ 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11 11:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n",
      "06/11 11:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_cfg = \"../configs/pointpillars/pointpillars_hydris_car.py\"\n",
    "deploy_cfg = \"../../mmdeploy/configs/mmdet3d/voxel-detection/voxel-detection_tensorrt_dynamic-kitti-32x4_fp16.py\"\n",
    "backend_files = \"deployed_models/hydris/end2end_fp16.engine\"\n",
    "img = \"../data/Hydris/training/velodyne/000001.bin\"\n",
    "device = \"cuda\"\n",
    "\n",
    "tensorrt_model = get_model(model_cfg,deploy_cfg,[backend_files],img,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False)[\"inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros((1000,4))\n",
    "torch_tensor = torch.tensor(p)\n",
    "a = {} \n",
    "a[\"inputs\"] = {}\n",
    "a[\"inputs\"][\"points\"] = [torch_tensor]\n",
    "b = tensorrt_model.data_preprocessor(a)\n",
    "b[\"inputs\"][\"voxels\"][\"voxels\"] = b[\"inputs\"][\"voxels\"][\"voxels\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 9.975194931030273 ms\n",
      "Inf: 1.264333724975586 ms\n",
      "Post: 15.738487243652344 ms\n",
      "Total: 26.99875831604004 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "s2 =time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 13.08298110961914 ms\n",
      "Inf: 0.8113384246826172 ms\n",
      "Post: 15.533208847045898 ms\n",
      "Total: 29.454708099365234 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "s2 =time.time()\n",
    "preds  = bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmengine.config import Config\n",
    "from mmdet3d.models.dense_heads import Anchor3DHead\n",
    "\n",
    "model_cfg = \"/home/riccardo/LidarObjDetection2/mmdetection3d/configs/pointpillars/pointpillars_hv_secfpn_8xb6-160e_lidar_vegas_iris-3d-car.py\"\n",
    "cfg = Config.fromfile(model_cfg)\n",
    "\n",
    "cfg[\"model\"][\"bbox_head\"].pop(\"type\")\n",
    "bbox_head = Anchor3DHead(**cfg[\"model\"][\"bbox_head\"])\n",
    "bbox_head.test_cfg = cfg[\"model\"][\"test_cfg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/10 12:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n",
      "06/10 12:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_cfg = \"../configs/pointpillars/pointpillars_hv_secfpn_8xb6-160e_lidar_vegas_iris-3d-car.py\"\n",
    "deploy_cfg = \"../../mmdeploy/configs/mmdet3d/voxel-detection/voxel-detection_tensorrt_dynamic-kitti-32x4_fp16.py\"\n",
    "backend_files = \"deployed_models/iris_360_2/end2end_fp16.engine\"\n",
    "img = \"../data/Dataset_Lidar_20240111_vegas_ontrack_01/training/velodyne/000001.bin\"\n",
    "device = \"cuda\"\n",
    "\n",
    "tensorrt_model = get_model(model_cfg,deploy_cfg,[backend_files],img,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 16.86406135559082 ms\n",
      "Inf: 5.480051040649414 ms\n",
      "Post: 28.685331344604492 ms\n",
      "Total: 51.058053970336914 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "s2 =time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: The GLFW library is not initialized\u001b[0;m\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "from mmdet3d.structures import Det3DDataSample\n",
    "ds = Det3DDataSample()\n",
    "ds.pred_instances_3d = preds[0]\n",
    "\n",
    "inferencer.visualize([{\"points\": pcl_path}], [ds],show=True,pred_score_thr=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelization algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.models.data_preprocessors import Det3DDataPreprocessor\n",
    "\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, device=\"cuda\",data_samples=False, deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[-60, -19.84, -3, 79.52, 19.84, 3],\n",
    "                # point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 3],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000),\n",
    "                deterministic=deterministic))\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non deterministic voxel -> 3.5941600799560547\n",
      "Deterministic voxel -> 4.848241806030273\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False, deterministic=False, device=\"cuda\")[\"inputs\"]\n",
    "print(\"Non deterministic voxel -> \" +str((time.time()-s0)*1000))\n",
    "\n",
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False, deterministic=True, device=\"cuda\")[\"inputs\"]\n",
    "print(\"Deterministic voxel -> \" +str((time.time()-s0)*1000))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0c343fece975dd89087e8c2194dd4d3db28d7000f1b32ed9ed9d584dd54dbbe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
