{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home/riccardo/mmdetection3d\")\n",
    "# sys.path.append(\"/root/workspace/mmdeploy\")\n",
    "from mmdet3d.apis import LidarDet3DInferencer\n",
    "from mmdeploy.apis.inference import inference_model\n",
    "from mmdeploy.apis.inference import get_model\n",
    "import os\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "import onnxruntime as ort\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "from mmdet3d.models.layers import box3d_multiclass_nms\n",
    "from mmdet3d.structures import limit_period, xywhr2xyxyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ~/code/polimove_nn_models/pointpillars_perception/iter_18000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "/home/riccardo/code/polimove_nn_models/pointpillars_perception/iter_18000.pth can not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# initialize inferencer \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# execute >> pip install -v -e . in mmdetection3d folder \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# CHANGE THE center_mode in loca_visualizer accordingly (KITTI -> center_mode = 'lidar_bottom', CUSTOM -> center_mode = whatever)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# inferencer = LidarDet3DInferencer(\"pointpillars_hydris_car\",scope=\"mmdet3d\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# inferencer = LidarDet3DInferencer(\"pointpillars_hydris_car\",scope=\"mmdet3d\")\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m inferencer \u001b[38;5;241m=\u001b[39m \u001b[43mLidarDet3DInferencer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpointpillars_hydris_v3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmmdet3d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/workspace/mmdetection3d/mmdet3d/apis/inferencers/lidar_det3d_inferencer.py:60\u001b[0m, in \u001b[0;36mLidarDet3DInferencer.__init__\u001b[0;34m(self, model, weights, device, scope, palette)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m              model: Union[ModelType, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m              weights: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# A global counter tracking the number of frames processed, for\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# naming of the output results\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_visualized_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLidarDet3DInferencer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpalette\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/workspace/mmdetection3d/mmdet3d/apis/inferencers/base_3d_inferencer.py:74\u001b[0m, in \u001b[0;36mBase3DInferencer.__init__\u001b[0;34m(self, model, weights, device, scope, palette)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;241m=\u001b[39m palette\n\u001b[1;32m     73\u001b[0m init_default_scope(scope)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m revert_sync_batchnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/infer/infer.py:180\u001b[0m, in \u001b[0;36mBaseInferencer.__init__\u001b[0;34m(self, model, weights, device, scope, show_progress)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pipeline(cfg)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_collate(cfg)\n",
      "File \u001b[0;32m/root/workspace/mmdetection3d/mmdet3d/apis/inferencers/base_3d_inferencer.py:103\u001b[0m, in \u001b[0;36mBase3DInferencer._init_model\u001b[0;34m(self, cfg, weights, device)\u001b[0m\n\u001b[1;32m    100\u001b[0m cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    101\u001b[0m model \u001b[38;5;241m=\u001b[39m MODELS\u001b[38;5;241m.\u001b[39mbuild(cfg\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 103\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_meta\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m checkpoint\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# mmdet3d 1.x\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     model\u001b[38;5;241m.\u001b[39mdataset_meta \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_meta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/checkpoint.py:636\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(model, filename, map_location, strict, logger, revise_keys)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(model,\n\u001b[1;32m    612\u001b[0m                     filename,\n\u001b[1;32m    613\u001b[0m                     map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    614\u001b[0m                     strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    615\u001b[0m                     logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    616\u001b[0m                     revise_keys\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^module\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)]):\n\u001b[1;32m    617\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load checkpoint from a file or URI.\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m        dict or OrderedDict: The loaded checkpoint.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43m_load_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;66;03m# OrderedDict is a subclass of dict\u001b[39;00m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/checkpoint.py:548\u001b[0m, in \u001b[0;36m_load_checkpoint\u001b[0;34m(filename, map_location, logger)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_checkpoint\u001b[39m(filename, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    532\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load checkpoint from somewhere (modelzoo, file, url).\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        information, which depends on the checkpoint.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointLoader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/checkpoint.py:330\u001b[0m, in \u001b[0;36mCheckpointLoader.load_checkpoint\u001b[0;34m(cls, filename, map_location, logger)\u001b[0m\n\u001b[1;32m    325\u001b[0m class_name \u001b[38;5;241m=\u001b[39m checkpoint_loader\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    326\u001b[0m print_log(\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoads checkpoint by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name[\u001b[38;5;241m10\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend from path: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    329\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheckpoint_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/checkpoint.py:346\u001b[0m, in \u001b[0;36mload_from_local\u001b[0;34m(filename, map_location)\u001b[0m\n\u001b[1;32m    344\u001b[0m filename \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mexpanduser(filename)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m osp\u001b[38;5;241m.\u001b[39misfile(filename):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m can not be found.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    347\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filename, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m checkpoint\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /home/riccardo/code/polimove_nn_models/pointpillars_perception/iter_18000.pth can not be found."
     ]
    }
   ],
   "source": [
    "# initialize inferencer \n",
    "# execute >> pip install -v -e . in mmdetection3d folder \n",
    "# CHANGE THE center_mode in loca_visualizer accordingly (KITTI -> center_mode = 'lidar_bottom', CUSTOM -> center_mode = whatever)\n",
    "\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car')\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_donaset_container-car')\n",
    "# inferencer = LidarDet3DInferencer('pointpillars_kittilidar-car') \n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hv_secfpn_8xb6-160e_lidar_vegas_iris-3d-car\",scope=\"mmdet3d\")\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_lidar_vegas_iris-car_360\",scope=\"mmdet3d\")\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hydris_car\",scope=\"mmdet3d\")\n",
    "# inferencer = LidarDet3DInferencer(\"pointpillars_hydris_car\",scope=\"mmdet3d\")\n",
    "inferencer = LidarDet3DInferencer(\"pointpillars_iris_v1\",scope=\"mmdet3d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/mnt/ssd/Datasets/DatasetForTraining/HYDRIS_v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination folder '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation' created.\n",
      "Copied '000623.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000502.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000807.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000987.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000939.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000705.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000859.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000542.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000075.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '001018.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000678.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000427.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000889.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000616.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000929.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000670.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000879.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000899.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000950.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000942.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000839.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000268.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000603.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000531.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000406.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000824.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000574.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000491.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '001003.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000020.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000468.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000970.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '001013.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000765.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000676.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000852.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000082.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000217.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000612.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000887.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000524.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000114.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000969.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000089.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000492.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000281.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '001032.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000527.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000347.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000857.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000647.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000497.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000780.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000680.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000169.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000262.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000564.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '001001.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000228.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000147.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000381.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000277.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000724.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000949.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000002.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000932.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000318.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000333.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000410.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000109.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '001000.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000284.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000550.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000331.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000295.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000310.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000325.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000144.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000861.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000620.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000663.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000283.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000536.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000622.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000098.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000629.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000776.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000018.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000965.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000420.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000630.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000791.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000507.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000723.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000518.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000645.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000718.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000340.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000362.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000755.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000688.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000876.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000138.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n",
      "Copied '000301.bin' to '/mnt/ssd/Datasets/HYDRA/2023-01-07_14-58/TrainingDataset_normalized/validation'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def copy_bin_files(source_txt, bin_folder_path,destination_folder):\n",
    "\n",
    "\n",
    "  # Check if source text file exists\n",
    "  if not os.path.exists(source_txt):\n",
    "    print(f\"Error: Source text file '{source_txt}' does not exist.\")\n",
    "    return\n",
    "\n",
    "  # Check if destination folder exists, create it if not\n",
    "  if not os.path.exists(destination_folder):\n",
    "    try:\n",
    "      os.makedirs(destination_folder)\n",
    "      print(f\"Destination folder '{destination_folder}' created.\")\n",
    "    except OSError as e:\n",
    "      print(f\"Error creating destination folder: {e}\")\n",
    "      return\n",
    "\n",
    "  # Open the source text file\n",
    "  try:\n",
    "    with open(source_txt, 'r') as file:\n",
    "      lines = file.readlines()\n",
    "  except OSError as e:\n",
    "    print(f\"Error opening source text file: {e}\")\n",
    "    return\n",
    "\n",
    "  # Process each line in the text file\n",
    "  for line in lines:\n",
    "    # Remove leading/trailing whitespace and newline character\n",
    "    filename = line.strip() +\".bin\"\n",
    "\n",
    "    # Check if the filename ends with .bin\n",
    "    if not filename.endswith('.bin'):\n",
    "      print(f\"Warning: Skipping non-binary file '{filename}'.\")\n",
    "      continue\n",
    "\n",
    "    # Construct source and destination paths\n",
    "    source_path = os.path.join(bin_folder_path, filename)\n",
    "    dest_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "    # Check if source file exists\n",
    "    if not os.path.exists(source_path):\n",
    "      print(f\"Warning: Source file '{source_path}' does not exist. Skipping...\")\n",
    "      continue\n",
    "\n",
    "    # Copy the file\n",
    "    try:\n",
    "      with open(source_path, 'rb') as source, open(dest_path, 'wb') as destination:\n",
    "        for chunk in iter(lambda: source.read(1024), b''):\n",
    "          destination.write(chunk)\n",
    "      print(f\"Copied '{filename}' to '{destination_folder}'.\")\n",
    "    except OSError as e:\n",
    "      print(f\"Error copying file '{filename}': {e}\")\n",
    "\n",
    "# Example usage\n",
    "source_txt_path = dataset_dir +\"/ImageSets/val.txt\"  # Replace with your actual path\n",
    "destination_folder_path = dataset_dir +\"/validation\"  # Replace with your actual path\n",
    "bin_folder_path = dataset_dir +\"/training/velodyne\"\n",
    "copy_bin_files(source_txt_path, bin_folder_path, destination_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/riccardo/LidarObjDetection2/mmdetection3d/work_dirs/pointpillars_hydris_v2_custom/iter_7000.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/ssd/Datasets/DatasetForTraining/HYDRIS_v2/validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m inferencer \u001b[38;5;241m=\u001b[39m LidarDet3DInferencer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpointpillars_hydris_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m,scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmdet3d\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m pcl \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_dir,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcl\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[1;32m      5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(points\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pcl,file))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/ssd/Datasets/DatasetForTraining/HYDRIS_v2/validation'"
     ]
    }
   ],
   "source": [
    "inferencer = LidarDet3DInferencer(\"pointpillars_hydris_v2\",scope=\"mmdet3d\")\n",
    "pcl = os.path.join(dataset_dir,\"validation\")\n",
    "for file in os.listdir(pcl):\n",
    "    print(file)\n",
    "    inputs = dict(points=os.path.join(pcl,file))\n",
    "    inf_res = inferencer(inputs, show=False,pred_score_thr=0.2, batch_size=1)\n",
    "    break\n",
    "inf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19472253,  0.45793188,  0.28935301,  0.23008776, -0.22189045,\n",
       "        0.36559498])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(inf_res[\"predictions\"][0][\"bboxes_3d\"])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000413.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "000228.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000241.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000163.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000040.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000335.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "000247.bin\n",
      "\u001b[1;33m[Open3D WARNING] [ViewControl] ConvertFromPinholeCameraParameters() failed because window height and width do not match.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: The GLFW library is not initialized\u001b[0;m\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "# pcl = '../data/Dataset_Lidar_20240111_vegas_ontrack_01/validation'\n",
    "pcl = os.path.join(dataset_dir,\"validation\")\n",
    "# pcl = os.path.join(dataset_dir,\"training\",\"velodyne\")\n",
    "# pcl = '../data/Hydra/training/velodyne/000020.bin'\n",
    "# pcl = '../data/DonaSet/training/velodyne/'\n",
    "# # pcl = './data/falcon/falcon1.bin'\n",
    "# inputs = dict(points=pcl)\n",
    "# inf_res = inferencer(inputs, show=True,pred_score_thr=0.3, batch_size=1)\n",
    "# inf_res\n",
    "\n",
    "for file in os.listdir(pcl):\n",
    "    print(file)\n",
    "    inputs = dict(points=os.path.join(pcl,file))\n",
    "    inf_res = inferencer(inputs, show=True,pred_score_thr=0.2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "inferencer(inputs, show=False,pred_score_thr=0.3,batch_size=1)\n",
    "end = time.time()\n",
    "print(\"Time Taken {} ms\".format((end-start)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.datasets.transforms.loading import (LoadAnnotations3D,\n",
    "                                                 LoadPointsFromFile)\n",
    "from mmdet3d.models.data_preprocessors.data_preprocessor import \\\n",
    "    Det3DDataPreprocessor\n",
    "from mmdet3d.datasets.transforms.formating import Pack3DDetInputs\n",
    "import os \n",
    "\n",
    "def prepare_input(inputs,batch_size=1):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000)))\n",
    "\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if i == max-1:\n",
    "            print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "s = time.time()\n",
    "\n",
    "prep_input = prepare_input({\"points\": pcl}, batch_size=1) # Preprocess\n",
    "res = model(prep_input[\"inputs\"],prep_input[\"data_samples\"], mode=\"tensor\") # Forward\n",
    "preds  = model.bbox_head.predict_by_feat(*res) # Postprocess\n",
    "\n",
    "print(\"Time: {} ms\".format((time.time()-s)*1000))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_res = inferencer(inputs, show=False,pred_score_thr=0.3, batch_size=4)\n",
    "inf_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Manually the tensor to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.models.dense_heads.anchor3d_head import Anchor3DHead\n",
    "\n",
    "# bbox_head=dict(\n",
    "#     type='Anchor3DHead',\n",
    "#     num_classes=3,\n",
    "#     in_channels=384,\n",
    "#     feat_channels=384,\n",
    "#     use_direction_classifier=True,\n",
    "#     assign_per_class=True,\n",
    "#     anchor_generator=dict(\n",
    "#         type='AlignedAnchor3DRangeGenerator',\n",
    "#         ranges=[\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -0.6, 69.12, 39.68, -0.6],\n",
    "#             [0, -39.68, -1.78, 69.12, 39.68, -1.78],\n",
    "#         ],\n",
    "#         sizes=[[0.8, 0.6, 1.73], [1.76, 0.6, 1.73], [3.9, 1.6, 1.56]],\n",
    "#         rotations=[0, 1.57],\n",
    "#         reshape_out=False),\n",
    "#     diff_rad_by_sin=True,\n",
    "#     bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder')\n",
    "# )\n",
    "# model.bbox_head\n",
    "head = Anchor3DHead(\n",
    "    num_classes=1,\n",
    "    in_channels=384,\n",
    "    feat_channels=384,\n",
    "    use_direction_classifier=True,\n",
    "    assign_per_class=True,\n",
    "    anchor_generator=dict(\n",
    "                type='AlignedAnchor3DRangeGenerator',\n",
    "                ranges=[[0, -39.68, -1.78, 69.12, 39.68, -1.78]],\n",
    "                sizes=[[3.9, 1.6, 1.56]],\n",
    "                rotations=[0, 1.57],\n",
    "                reshape_out=True),\n",
    "    diff_rad_by_sin=True,\n",
    "    bbox_coder=dict(type='DeltaXYZWLHRBBoxCoder'),\n",
    "    test_cfg=model.test_cfg\n",
    "    )\n",
    "# preds  = head.predict_by_feat(*res)\n",
    "preds  = model.bbox_head.predict_by_feat(*res)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][\"bboxes_3d\"],pred_res[0][\"bboxes_3d\"],inf_res[\"predictions\"][0][\"bboxes_3d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inferencer.model\n",
    "pcl_path = os.path.join(dataset_dir, \"training/velodyne/000020.bin\")\n",
    "model_path = \"deployed_models/hydris/end2end.onnx\"\n",
    "model_cfg = \"../configs/pointpillars/custom/pointpillars_hydris_v2_custom.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, model_cfg = None, device=\"cuda\",data_samples=False, deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        cfg = Config.fromfile(model_cfg)\n",
    "        cfg[\"model\"][\"data_preprocessor\"].pop(\"type\")\n",
    "        preprocessor = Det3DDataPreprocessor(**cfg[\"model\"][\"data_preprocessor\"])\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 24.716854095458984 ms\n",
      "Inf: 595.7653522491455 ms\n",
      "Post: 9.233951568603516 ms\n",
      "Total: 605.0784587860107 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "model.cpu()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg=model_cfg,device = \"cpu\")[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-62.3512, -21.5698, -12.2966,   0.4070,   0.1621,   0.1149,  -0.8427])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/Datasets/DatasetForTraining/HYDRIS_v2/training/velodyne/000020.bin'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 16.695499420166016 ms\n",
      "Inf: 75.1815140247345 ms\n",
      "Post: 4.874944686889648 ms\n",
      "Total: 87.40043640136719 ms\n"
     ]
    }
   ],
   "source": [
    "pcl_base = \"/mnt/ssd/Datasets/DatasetForTraining/HYDRIS_v2/training/velodyne/\"\n",
    "pcl_path = os.path.join(pcl_base, \"000000.bin\")\n",
    "s0 = time.time()\n",
    "model.cuda()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg =  model_cfg, deterministic=True)[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "torch.cuda.current_stream().synchronize()\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "sum = 0\n",
    "times = 8\n",
    "for i in range(times):\n",
    "    pcl_path = os.path.join(pcl_base,\"00000\"+str(i)+\".bin\")\n",
    "    s0 = time.time()\n",
    "    inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg =  model_cfg, deterministic=True)[\"inputs\"]\n",
    "    s1 = time.time()\n",
    "    val_output = model(inputs,mode=\"tensor\")\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    s2 = time.time()\n",
    "    sum+=s2-s1\n",
    "\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format(sum/times*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Provider (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 21:42:14.795581750 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-08-26 01:42:14 WARNING] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "2024-08-25 21:42:14.795620088 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-08-26 01:42:14 WARNING] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n",
      "2024-08-25 21:42:22.271920833 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-08-26 01:42:22 WARNING] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "2024-08-25 21:42:22.271967078 [W:onnxruntime:Default, tensorrt_execution_provider.h:75 log] [2024-08-26 01:42:22 WARNING] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ort_sess \u001b[38;5;241m=\u001b[39m \u001b[43mort\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mproviders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTensorrtExecutionProvider\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUDAExecutionProvider\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCPUExecutionProvider\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:383\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:435\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    432\u001b[0m     disabled_optimizers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(disabled_optimizers)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# initialize the C++ InferenceSession\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess \u001b[38;5;241m=\u001b[39m sess\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess\u001b[38;5;241m.\u001b[39msession_options\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcl_path = \"/mnt/ssd/Datasets/DatasetForTraining/HYDRIS_v2/training/velodyne/000030.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcl_base = \"/mnt/ssd/Datasets/DatasetForTraining/HYDRIS_v2/training/velodyne/\"\n",
    "pcl_path = os.path.join(pcl_base, \"000000.bin\")\n",
    "s0 = time.time()\n",
    "model.cuda()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg =  model_cfg, deterministic=True)[\"inputs\"]\n",
    "\n",
    "s1 = time.time()\n",
    "val_output = model(inputs,mode=\"tensor\")\n",
    "torch.cuda.current_stream().synchronize()\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "\n",
    "sum = 0\n",
    "times = 8\n",
    "for i in range(times):\n",
    "    pcl_path = os.path.join(pcl_base,\"00000\"+str(i)+\".bin\")\n",
    "    s0 = time.time()\n",
    "    inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg =  model_cfg, deterministic=True)[\"inputs\"]\n",
    "    s1 = time.time()\n",
    "    outputs = ort_sess.run(None, onnx_inputs)\n",
    "    s2 = time.time()\n",
    "    outputs = [arr.astype(np.float32) for arr in outputs]\n",
    "    preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "    sum+=s2-s1\n",
    "\n",
    "preds  = model.bbox_head.predict_by_feat(*val_output)\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format(sum/times*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 28.67412567138672 ms\n",
      "Inf: 46.817779541015625 ms\n",
      "Post: 6.3571929931640625 ms\n",
      "Total: 81.88557624816895 ms\n"
     ]
    }
   ],
   "source": [
    "s0= time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg = model_cfg, device=\"cuda\")[\"inputs\"]\n",
    "\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy().astype(np.float32), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "outputs = [arr.astype(np.float32) for arr in outputs]\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Provider (ONNX Runtime) - FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxconverter_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxmltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import load\n",
    "from onnxmltools.utils.float16_converter import convert_float_to_float16\n",
    "from onnx import save\n",
    "onnx_model = load(model_path)\n",
    "new_onnx_model = convert_float_to_float16(onnx_model)\n",
    "save(new_onnx_model,\"deployed_models/hydra/end2end_fp16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(\"deployed_models/hydra/end2end_fp16.onnx\",providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0= time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, model_cfg = model_cfg,device=\"cuda\")[\"inputs\"]\n",
    "\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy().astype(np.float16), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "outputs = [arr.astype(np.float32) for arr in outputs]\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Provider  (ONNX Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession(model_path,providers=[ 'CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1)[\"inputs\"]\n",
    "onnx_inputs = {'voxels': inputs[\"voxels\"][\"voxels\"].cpu().numpy(), 'coors':inputs[\"voxels\"][\"coors\"].cpu().numpy(),'num_points':inputs[\"voxels\"][\"num_points\"].cpu().numpy()}\n",
    "\n",
    "s1 = time.time()\n",
    "outputs = ort_sess.run(None, onnx_inputs)\n",
    "s2 = time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(*outputs)\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, model_cfg = None, device=\"cuda\",data_samples=False, preprocessor=None,deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    # print(preprocessor.device)\n",
    "    s0 = time.time()\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    # print((time.time()-s0)*1000)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/03 09:15:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "09/03 09:15:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"mmdet3d_tasks\" registry tree. As a workaround, the current \"mmdet3d_tasks\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "09/03 09:15:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"backend_voxel_detectors\" registry tree. As a workaround, the current \"backend_voxel_detectors\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "09/03 09:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n",
      "09/03 09:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_cfg = \"../configs/pointpillars/custom/pointpillars_hydris_v3_custom.py\"\n",
    "deploy_cfg = \"../../mmdeploy/configs/mmdet3d/voxel-detection/voxel-detection_tensorrt_dynamic-kitti-32x4_fp16.py\"\n",
    "backend_files = \"deployed_models/hydris/end2end_fp16.engine\"\n",
    "img = os.path.join(dataset_dir,\"training/velodyne/000000.bin\")\n",
    "device = \"cuda\"\n",
    "\n",
    "tensorrt_model = get_model(model_cfg,deploy_cfg,[backend_files],img,device)\n",
    "preprocessor = tensorrt_model.data_preprocessor.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(model_cfg)\n",
    "cfg[\"model\"][\"data_preprocessor\"][\"voxel_layer\"][\"deterministic\"] = False\n",
    "cfg[\"model\"][\"data_preprocessor\"].pop(\"type\")\n",
    "\n",
    "preprocessor = Det3DDataPreprocessor(**cfg[\"model\"][\"data_preprocessor\"]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 4.663944244384766 ms\n",
      "Inf: 14.341354370117188 ms\n",
      "Post: 6.198644638061523 ms\n",
      "Total: 25.243759155273438 ms\n"
     ]
    }
   ],
   "source": [
    "pcl_path =  os.path.join(dataset_dir,\"training/velodyne/000012.bin\")\n",
    "\n",
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, preprocessor = preprocessor, data_samples=False)[\"inputs\"]\n",
    "# inputs = prepare_input_fast({\"points\": pcl_path}, batch_size=1, data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "res[\"bbox_pred\"][0] = res[\"bbox_pred\"][0].to(\"cpu\",non_blocking=True)\n",
    "res[\"cls_score\"][0] = res[\"cls_score\"][0].to(\"cpu\",non_blocking=True)\n",
    "res[\"dir_cls_pred\"][0] = res[\"dir_cls_pred\"][0].to(\"cpu\",non_blocking=True)\n",
    "torch.cuda.synchronize()\n",
    "# combined_tensor = torch.cat([res[\"bbox_pred\"][0], res[\"cls_score\"][0], res[\"dir_cls_pred\"][0]], dim=0)\n",
    "# combined_cpu = combined_tensor.cpu()\n",
    "s2 =time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = preds[0].scores_3d\n",
    "bboxes = preds[0].bboxes_3d.center\n",
    "yaws = preds[0].bboxes_3d.yaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 5.271673202514648 ms\n",
      "Inf: 1.4641284942626953 ms\n",
      "Post: 78.20892333984375 ms\n",
      "Total: 84.9771499633789 ms\n"
     ]
    }
   ],
   "source": [
    "pcl_path =  os.path.join(dataset_dir,\"training/velodyne/000012.bin\")\n",
    "\n",
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, preprocessor = preprocessor, data_samples=False)[\"inputs\"]\n",
    "# inputs = prepare_input_fast({\"points\": pcl_path}, batch_size=1, data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "# res[\"bbox_pred\"][0] = res[\"bbox_pred\"][0].to(\"cpu\",non_blocking=True)\n",
    "# res[\"cls_score\"][0] = res[\"cls_score\"][0].to(\"cpu\",non_blocking=True)\n",
    "# res[\"dir_cls_pred\"][0] = res[\"dir_cls_pred\"][0].to(\"cpu\",non_blocking=True)\n",
    "# combined_tensor = torch.cat([res[\"bbox_pred\"][0], res[\"cls_score\"][0], res[\"dir_cls_pred\"][0]], dim=0)\n",
    "# combined_cpu = combined_tensor.cpu()\n",
    "s2 =time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, device=\"cuda\"):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    # print(preprocessor.device)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(model_cfg)\n",
    "cfg[\"model\"][\"data_preprocessor\"][\"voxel_layer\"][\"deterministic\"] = False\n",
    "cfg[\"model\"][\"data_preprocessor\"].pop(\"type\")\n",
    "preprocessor = Det3DDataPreprocessor(**cfg[\"model\"][\"data_preprocessor\"]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = prepare_input({\"points\": pcl_path})\n",
    "# cloud[\"inputs\"][\"points\"][0].to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.41 ms  45.8 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preprocessor(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud[\"inputs\"][\"points\"][0] = cloud[\"inputs\"][\"points\"][0].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ms  60.5 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preprocessor(cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Res in cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "res[\"bbox_pred\"][0] = res[\"bbox_pred\"][0].to(\"cpu\",non_blocking=True)\n",
    "res[\"cls_score\"][0] = res[\"cls_score\"][0].to(\"cpu\",non_blocking=True)\n",
    "res[\"dir_cls_pred\"][0] = res[\"dir_cls_pred\"][0].to(\"cpu\",non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 s  50.6 s per loop (mean  std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = res[\"cls_score\"][0][0].permute(1, 2,0).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Res in gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tensorrt_model(inputs, mode=\"tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 s  397 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = res[\"cls_score\"][0][0].permute(1, 2,0).reshape(-1, 1)\n",
    "# a.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_score = res[\"cls_score\"][0][0].permute(1, 2,0).reshape(-1, 1)\n",
    "bbox_pred = res[\"bbox_pred\"][0][0].permute(1, 2, 0).reshape(-1, 7)\n",
    "dir_cls_pred = res[\"dir_cls_pred\"][0][0].permute(1, 2, 0).reshape(-1, 2)\n",
    "# scores=scores.to(\"cpu\")\n",
    "cls_score.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 s  5.51 s per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "scores_sig = cls_score.sigmoid()\n",
    "max_cls_score, _ = scores_sig.max(dim=1)\n",
    "max_scores_topk, topk_inds = max_scores.topk(10)\n",
    "max_scores_topk=max_scores_topk.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 s  839 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "max_scores, _ = cls_score.max(dim=1)\n",
    "max_scores_topk, topk_inds = max_scores.topk(10)\n",
    "max_scores_topk = max_scores_topk.sigmoid()\n",
    "max_scores_topk=max_scores_topk.to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -38.3125, -139.0000,  -66.2500,  ...,   -4.6641,   -3.7109,\n",
       "          -4.9922], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_score.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.7 s  5.54 s per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "scores=cls_score.reshape(-1)\n",
    "max_scores_topk, topk_inds = scores.topk(10)\n",
    "max_scores_topk = max_scores_topk.sigmoid()\n",
    "max_scores_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.8 s  922 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "max_scores, _ = cls_score.max(dim=1)\n",
    "max_scores_topk, topk_inds = max_scores.topk(10)\n",
    "max_scores_topk = max_scores_topk.sigmoid()\n",
    "max_scores_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.9 s  564 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dir_cls_score = torch.max(dir_cls_pred, dim=-1)[1]\n",
    "dir_cls_score = dir_cls_score[topk_inds]\n",
    "dir_cls_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.6 s  1.01 s per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dir_cls_score = dir_cls_pred[topk_inds]\n",
    "dir_cls_score = torch.max(dir_cls_score, dim=-1)[1]\n",
    "dir_cls_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124, 436])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"cls_score\"][0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968 s  18.2 s per loop (mean  std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "featmap_sizes = [res[\"cls_score\"][0][0][0].shape]\n",
    "mlvl_priors = model.bbox_head.prior_generator.grid_anchors(\n",
    "            featmap_sizes, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 s  63 s per loop (mean  std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "priors = mlvl_priors[0][topk_inds, :]\n",
    "bboxes = model.bbox_head.bbox_coder.decode(priors, bbox_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # if self.use_sigmoid_cls:\n",
    "                #     max_scores, _ = scores.max(dim=1)\n",
    "                # else:\n",
    "                #     max_scores, _ = scores[:, :-1].max(dim=1)\n",
    "                # _, topk_inds = max_scores.topk(nms_pre)\n",
    "                # priors = priors[topk_inds, :]\n",
    "                # bbox_pred = bbox_pred[topk_inds, :]\n",
    "                # scores = scores[topk_inds, :]\n",
    "                # dir_cls_score = dir_cls_score[topk_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "# res[\"bbox_pred\"][0] = res[\"bbox_pred\"][0].to(\"cpu\")\n",
    "# res[\"cls_score\"][0] = res[\"cls_score\"][0].to(\"cpu\")\n",
    "# res[\"dir_cls_pred\"][0] = res[\"dir_cls_pred\"][0].to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006699154999999735\n"
     ]
    }
   ],
   "source": [
    "t0 = time.process_time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "torch.cuda.current_stream().synchronize()\n",
    "t1= time.process_time()\n",
    "\n",
    "\n",
    "cls_score = res[\"cls_score\"][0][0].permute(1, 2,0).reshape(-1, 1)\n",
    "\n",
    "scores = cls_score.reshape(-1)\n",
    "max_scores_topk, topk_inds = scores.topk(10)\n",
    "max_scores_topk = max_scores_topk.sigmoid()\n",
    "\n",
    "dir_cls_pred = res[\"dir_cls_pred\"][0][0].permute(1, 2, 0).reshape(-1, 2)\n",
    "dir_cls_score = dir_cls_pred[topk_inds]\n",
    "dir_cls_score = torch.max(dir_cls_score, dim=-1)[1]\n",
    "\n",
    "bbox_pred = res[\"bbox_pred\"][0][0].permute(1, 2, 0).reshape(-1, 7)\n",
    "bbox_pred = bbox_pred[topk_inds, :]\n",
    "\n",
    "featmap_sizes = [res[\"cls_score\"][0][0][0].shape]\n",
    "\n",
    "mlvl_priors = model.bbox_head.prior_generator.grid_anchors(\n",
    "            featmap_sizes, device=\"cuda\")\n",
    "\n",
    "priors = mlvl_priors[0][topk_inds, :]\n",
    "\n",
    "\n",
    "bboxes = model.bbox_head.bbox_coder.decode(priors, bbox_pred)\n",
    "\n",
    "# %%timeit\n",
    "mlvl_scores = max_scores_topk.reshape(-1,1)\n",
    "padding = mlvl_scores.new_zeros(mlvl_scores.shape[0], 1)\n",
    "mlvl_scores = torch.cat([mlvl_scores, padding], dim=1)\n",
    "\n",
    "\n",
    "bboxes_for_nms = xywhr2xyxyr(bboxes[:,(0,1,3,4,6)])\n",
    "\n",
    "results = box3d_multiclass_nms(bboxes, bboxes[:,:5],\n",
    "                    mlvl_scores, 0.5,5,\n",
    "                        cfg[\"model\"][\"test_cfg\"], dir_cls_score)\n",
    "\n",
    "bboxes, scores, labels, dir_scores = results\n",
    "\n",
    "if bboxes.shape[0] > 0:\n",
    "    dir_rot = limit_period(bboxes[..., 6] - (-1.5707963267948966),\n",
    "                            0, np.pi)\n",
    "    bboxes[..., 6] = (\n",
    "        dir_rot + (-1.5707963267948966) +\n",
    "        np.pi * dir_scores.to(bboxes.dtype))\n",
    "# bboxes_cpu = bboxes.to(\"cpu\")\n",
    "# scores = scores.to(\"cpu\")\n",
    "print(time.process_time() - t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Inferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "from mmdet3d.models.dense_heads import Anchor3DHead\n",
    "\n",
    "cfg = Config.fromfile(model_cfg)\n",
    "\n",
    "cfg[\"model\"][\"bbox_head\"].pop(\"type\")\n",
    "bbox_head = Anchor3DHead(**cfg[\"model\"][\"bbox_head\"])\n",
    "bbox_head.test_cfg = cfg[\"model\"][\"test_cfg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre: 5.93256950378418 ms\n",
      "Inf: 15.146017074584961 ms\n",
      "Post: 3.1936168670654297 ms\n",
      "Total: 24.293184280395508 ms\n"
     ]
    }
   ],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1, preprocessor=preprocessor,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "torch.cuda.synchronize()\n",
    "s2 =time.time()\n",
    "preds  = bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT manual Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "def load_engine(engine_file_path):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with open(engine_file_path, 'rb') as f:\n",
    "        runtime = trt.Runtime(TRT_LOGGER)\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    return engine\n",
    "def torch_dtype_from_trt(dtype: trt.DataType) -> torch.dtype:\n",
    "    \"\"\"Convert pytorch dtype to TensorRT dtype.\n",
    "\n",
    "    Args:\n",
    "        dtype (str.DataType): The data type in tensorrt.\n",
    "\n",
    "    Returns:\n",
    "        torch.dtype: The corresponding data type in torch.\n",
    "    \"\"\"\n",
    "\n",
    "    if dtype == trt.bool:\n",
    "        return torch.bool\n",
    "    elif dtype == trt.int8:\n",
    "        return torch.int8\n",
    "    elif dtype == trt.int32:\n",
    "        return torch.int32\n",
    "    elif dtype == trt.float16:\n",
    "        return torch.float16\n",
    "    elif dtype == trt.float32:\n",
    "        return torch.float32\n",
    "    else:\n",
    "        raise TypeError(f'{dtype} is not supported by torch')\n",
    "\n",
    "\n",
    "def torch_device_from_trt(device: trt.TensorLocation):\n",
    "    \"\"\"Convert pytorch device to TensorRT device.\n",
    "\n",
    "    Args:\n",
    "        device (trt.TensorLocation): The device in tensorrt.\n",
    "    Returns:\n",
    "        torch.device: The corresponding device in torch.\n",
    "    \"\"\"\n",
    "    if device == trt.TensorLocation.DEVICE:\n",
    "        return torch.device('cuda')\n",
    "    elif device == trt.TensorLocation.HOST:\n",
    "        return torch.device('cpu')\n",
    "    else:\n",
    "        return TypeError(f'{device} is not supported by torch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcl_path =  os.path.join(dataset_dir,\"training/velodyne/000020.bin\")\n",
    "backend_files = \"deployed_models/hydris/end2end_fp16.engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322058/2476830997.py:4: DeprecationWarning: Use get_tensor_name instead.\n",
      "  input_names = [engine.get_binding_name(i) for i in range(n_inputs)]\n",
      "/tmp/ipykernel_322058/2476830997.py:5: DeprecationWarning: Use get_tensor_name instead.\n",
      "  output_names = [engine.get_binding_name(i) for i in range(n_inputs,n_inputs+n_outputs)]\n"
     ]
    }
   ],
   "source": [
    "n_inputs  = 3\n",
    "n_outputs = 3\n",
    "engine = load_engine(backend_files)\n",
    "input_names = [engine.get_binding_name(i) for i in range(n_inputs)]\n",
    "output_names = [engine.get_binding_name(i) for i in range(n_inputs,n_inputs+n_outputs)]\n",
    "\n",
    "# Create context\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(pcl_path):\n",
    "    bindings = [None] * (n_inputs + n_outputs)\n",
    "\n",
    "    # Transform Input\n",
    "    inputs = prepare_input({\"points\": pcl_path}, batch_size=1, preprocessor=preprocessor,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "    preprocessed = inputs['voxels']\n",
    "    input_dict = {\n",
    "        'voxels': preprocessed['voxels'].to(\"cuda\"),\n",
    "        'num_points': preprocessed['num_points'].to(\"cuda\"),\n",
    "        'coors': preprocessed['coors'].to(\"cuda\")\n",
    "    }\n",
    "    inputs = dict((name, data.contiguous().int() if data.dtype ==\n",
    "                        torch.long else data.contiguous())\n",
    "                        for name, data in input_dict.items())\n",
    "\n",
    "    for input_name in input_names:\n",
    "        idx = engine.get_binding_index(input_name)\n",
    "        profile = engine.get_profile_shape(0, input_name)\n",
    "        input_tensor = inputs[input_name]\n",
    "        context.set_binding_shape(idx, tuple(input_tensor.shape))\n",
    "        bindings[idx] = input_tensor.contiguous().data_ptr()\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = {}\n",
    "    for output_name in output_names:\n",
    "        idx = engine.get_binding_index(output_name)\n",
    "\n",
    "        dtype = torch_dtype_from_trt(engine.get_binding_dtype(idx))\n",
    "        shape = tuple(context.get_binding_shape(idx))\n",
    "\n",
    "        device = torch_device_from_trt(engine.get_location(idx))\n",
    "        output = torch.empty(size=shape, dtype=dtype, device=device)\n",
    "        outputs[output_name] = output\n",
    "        bindings[idx] = output.contiguous().data_ptr()\n",
    "\n",
    "    context.execute_async_v2(bindings,\n",
    "                            torch.cuda.current_stream().cuda_stream)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 20.28489112854004 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322058/1935469659.py:17: DeprecationWarning: Use get_tensor_name instead.\n",
      "  idx = engine.get_binding_index(input_name)\n",
      "/tmp/ipykernel_322058/1935469659.py:18: DeprecationWarning: Use get_tensor_profile_shape instead.\n",
      "  profile = engine.get_profile_shape(0, input_name)\n",
      "/tmp/ipykernel_322058/1935469659.py:20: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(idx, tuple(input_tensor.shape))\n",
      "/tmp/ipykernel_322058/1935469659.py:26: DeprecationWarning: Use get_tensor_name instead.\n",
      "  idx = engine.get_binding_index(output_name)\n",
      "/tmp/ipykernel_322058/1935469659.py:28: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = torch_dtype_from_trt(engine.get_binding_dtype(idx))\n",
      "/tmp/ipykernel_322058/1935469659.py:29: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shape = tuple(context.get_binding_shape(idx))\n",
      "/tmp/ipykernel_322058/1935469659.py:31: DeprecationWarning: Use get_tensor_location instead.\n",
      "  device = torch_device_from_trt(engine.get_location(idx))\n"
     ]
    }
   ],
   "source": [
    "s0=time.time()\n",
    "do_inference(pcl_path)\n",
    "torch.cuda.synchronize()\n",
    "print(\"Took \"+str((time.time()-s0)*1e3)+\" ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "context.execute_async_v2(bindings,\n",
    "                        torch.cuda.current_stream().cuda_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 124, 436])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"cls_score0\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model_cfg = \"../configs/pointpillars/pointpillars_hydris_car.py\"\n",
    "deploy_cfg = \"../../mmdeploy/configs/mmdet3d/voxel-detection/voxel-detection_tensorrt_dynamic-kitti-32x4_fp16.py\"\n",
    "backend_files = \"deployed_models/hydra/end2end_fp16.engine\"\n",
    "img =  os.path.join(dataset_dir,\"velodyne/000000.bin\")\n",
    "device = \"cuda\"\n",
    "\n",
    "tensorrt_model = get_model(model_cfg,deploy_cfg,[backend_files],img,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "\n",
    "s1=time.time()\n",
    "res = tensorrt_model(inputs, mode=\"tensor\")\n",
    "s2 =time.time()\n",
    "preds  = model.bbox_head.predict_by_feat(res[\"cls_score\"],res[\"bbox_pred\"],res[\"dir_cls_pred\"])\n",
    "print(\"Pre: {} ms\".format((s1-s0)*1000))\n",
    "print(\"Inf: {} ms\".format((s2-s1)*1000))\n",
    "print(\"Post: {} ms\".format((time.time()-s2)*1000))\n",
    "print(\"Total: {} ms\".format((time.time()-s0)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(preds[0].bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dict(points=pcl)\n",
    "inf_res = inferencer(inputs, show=True, pred_score_thr=0.3, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.structures import Det3DDataSample\n",
    "\n",
    "inputs = prepare_input({\"points\": pcl}, batch_size=1,model_cfg=model_cfg,data_samples=False)[\"inputs\"]\n",
    "preds = tensorrt_model(inputs, mode=\"predict\")\n",
    "ds = Det3DDataSample()\n",
    "ds.pred_instances_3d = preds[0]\n",
    "\n",
    "inferencer.visualize([{\"points\": pcl}], [ds],show=True,pred_score_thr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(inf_res[\"predictions\"][0][\"bboxes_3d\"][0]) -  list(ds.pred_instances_3d.bboxes_3d.cpu())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelization algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.models.data_preprocessors import Det3DDataPreprocessor\n",
    "\n",
    "\n",
    "def prepare_input(inputs,batch_size=1, device=\"cuda\",data_samples=False, deterministic=True):\n",
    "    model_inputs = {}\n",
    "    model_inputs[\"inputs\"] = {}\n",
    "    model_inputs[\"inputs\"][\"points\"] = []\n",
    "    if data_samples:\n",
    "        model_inputs[\"data_samples\"] = []\n",
    "    max = batch_size\n",
    "\n",
    "    files = []\n",
    "    if not os.path.isdir(inputs[\"points\"]):\n",
    "        files.append(inputs[\"points\"])\n",
    "    else:\n",
    "        files = [inputs[\"points\"] + s for s in os.listdir(inputs[\"points\"])]\n",
    "    for i,sample_path in enumerate(files):\n",
    "        inp = {}\n",
    "        inp[\"lidar_points\"] = {}\n",
    "        inp[\"lidar_points\"][\"lidar_path\"] = sample_path\n",
    "\n",
    "\n",
    "        loader = LoadPointsFromFile(coord_type='LIDAR',load_dim=4,use_dim=4)\n",
    "        packer = Pack3DDetInputs(keys=['points'])\n",
    "\n",
    "        voxel_size = [0.16, 0.16, 4]\n",
    "        preprocessor = Det3DDataPreprocessor(\n",
    "            voxel=True,\n",
    "            voxel_layer=dict(\n",
    "                max_num_points=32,  # max_points_per_voxel\n",
    "                point_cloud_range=[-60, -19.84, -3, 79.52, 19.84, 3],\n",
    "                # point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 3],\n",
    "                voxel_size=voxel_size,\n",
    "                max_voxels=(16000, 40000),\n",
    "                deterministic=deterministic))\n",
    "        if not deterministic:\n",
    "            preprocessor.cuda()\n",
    "        input = loader(inp)\n",
    "        input = packer(input)\n",
    "        # input[\"inputs\"][\"points\"] = input[\"inputs\"][\"points\"].cuda()\n",
    "        model_inputs[\"inputs\"][\"points\"].append(input[\"inputs\"][\"points\"])\n",
    "        if data_samples:\n",
    "            model_inputs[\"data_samples\"].append(input[\"data_samples\"])\n",
    "        if i == max-1:\n",
    "            # print(\"Batch Size!\")\n",
    "            break\n",
    "    prep_input = preprocessor(model_inputs)\n",
    "    if device == \"cuda\":\n",
    "        prep_input[\"inputs\"][\"voxels\"][\"voxels\"] = prep_input[\"inputs\"][\"voxels\"][\"voxels\"].cuda()\n",
    "    return prep_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False, deterministic=False, device=\"cuda\")[\"inputs\"]\n",
    "print(\"Non deterministic voxel -> \" +str((time.time()-s0)*1000))\n",
    "\n",
    "s0 = time.time()\n",
    "inputs = prepare_input({\"points\": pcl_path}, batch_size=1,data_samples=False, deterministic=True, device=\"cuda\")[\"inputs\"]\n",
    "print(\"Deterministic voxel -> \" +str((time.time()-s0)*1000))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0c343fece975dd89087e8c2194dd4d3db28d7000f1b32ed9ed9d584dd54dbbe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
